{include journal.html with}
  title: Resource Management in Python Generators
  publish_date: 2022-09-03
  content: {*
    {q}
      <p>
        Wow, I've never thought I'd struggle with resource management in
        <em>Python</em> of all languages. But I did, while writing the HTML
        preprocessor for this website a couple days ago.
      </p>
        
      <p>
        As my preprocessor parses a file, the source text is sometimes meant to
        be directly written as output and sometimes saved in memory for later.
        I have two functions, <code>parse_file</code> and
        <code>parse_with</code>, to handle the two contexts. The source file is
        passed between them. For example, once <code>parse_file</code> finds
        <code>&lbrace;with}</code>, a directive that indicates the start of a block,
        on a line, it'll call <code>parse_with</code> to process the text until
        the end of that block.
      </p>

      <p>
        However, if I simply iterated over the file with a for loop in either
        function, I could only start with the line <em>after</em> the line with
        the <code>&lbrace;with}</code> directive. I need to pass the remainder
        of the directive line as a parameter to <code>parse_with</code> and
        have it process the remainder before iterating through the file.
        Unfortunately, this addition turned a simple for loop into an unwieldy
        combination of a while loop and a try-except clause:
      </p>

      {pre code}
def parse_with(file, remainder):
    line = remainder
    while True:
        [process line]
        try:
            line = next(file)
        except StopIteration:
            return
      {endpre}

      <p>
        Never until then have I longed for a do-while loop in any language...
        Even then, it probably would've still been clunky, as iterators always
        throw an exception upon exhaustion. This was where generators came in.
        All I needed was an iterator that "prepends" the remainder before the
        items generated by the file iterator. Here's the first generator
        function I wrote:
      </p>

      {pre code}
def prepend_iter(remainder, file):
    if remainder:
        yield remainder
    yield from file
      {endpre}

      {with}
        stackoverflow: https://stackoverflow.com/a/26109157/12702027
        pep: https://peps.python.org/pep-0380/#finalization
      {endwith}

      <p>
        Simple, isn't it? Just yield the remainder if any, then delegate the
        rest of the work to the file with a fancy <em>transparent bidirectional
        connection!</em> (as <a href="{stackoverflow}">this Stack Overflow
        answer</a> puts it) Then, I could have a nice clean for loop in
        <code>parse_with</code>:
      </p>

      {pre code}
def parse_with(file, remainder):
    for line in prepend_iter(remainder, file):
        [process line]
      {endpre}

      <p> But then, my joy was suddenly cut short by this: </p>

      {pre samp}
Traceback (most recent call last):
  File "/usr/share/nginx/html/jcfp.site/scripts/parse-file", line 166, in <module>
    parse_file(file, sys.stdout)
  File "/usr/share/nginx/html/jcfp.site/scripts/parse-file", line 109, in parse_file
    line = parse_with(src, include_subs, subs, line)
  File "/usr/share/nginx/html/jcfp.site/scripts/parse-file", line 57, in parse_with
    line = parse_file(src, str_buf, subs, match[1] + "}",
  File "/usr/share/nginx/html/jcfp.site/scripts/parse-file", line 121, in parse_file
    line = parse_file(src, str_buf, subs, "{endq}", line)
  File "/usr/share/nginx/html/jcfp.site/scripts/parse-file", line 74, in parse_file
    for line in prepend_iter(rem, src):
  File "/usr/share/nginx/html/jcfp.site/scripts/parse-file", line 26, in prepend_iter
    yield from src
ValueError: I/O operation on closed file.
      {endpre}

      <p>
        How could I possibly have closed the file? My topmost
        <code>parse_file</code> hasn't even returned, so Python couldn't have
        closed it for being out of scope. After hours of reading Stack Overflow
        threads and scouring through PEPs, I found the answer in <a
        href="{pep}">this little section of PEP 380.</a> (I had actually
        skipped it the first time because its first paragraph seemed to imply
        the opposite of what it says.) Essentially, a <code>yield with</code>
        statement <em>closes the subiterator</em> if the outer generator gets
        closed, even if the subiterator hasn't been exhausted. So when
        <code>parse_with</code> returns, the generator created by
        <code>prepend_iter</code> gets freed, closing the file iterator used by
        the generator. The solution, fortunately, was just one extra line:
      </p>

      {pre code}
def prepend_iter(remainder, file):
    if remainder:
        yield reminder
    for line in file:
        yield line
      {endpre}

      <p>
        Clearly, <code>yield with</code> does much more than delegate
        iteration. The <a href="{stackoverflow}">Stack Overflow answer</a> I
        linked before shows some more sophisticated usages. It seems like
        magic that just works, but that also means more unexpected pitfalls. Be
        especially careful when yielding from a shared iterator!
      </p>
    {endq}
  *}
{endwith}
